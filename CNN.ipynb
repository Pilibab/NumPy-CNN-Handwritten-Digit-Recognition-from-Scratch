{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de812f2",
   "metadata": {},
   "source": [
    "# __Implementing CNN (Convulusion Neural Network) from scratch__\n",
    "### without machine learning library and with numpy and pandas only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4072c8d9",
   "metadata": {},
   "source": [
    "##### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6a9552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library \n",
    "import os \n",
    "import numpy as np \n",
    "import struct \n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8264f9",
   "metadata": {},
   "source": [
    "##### const variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016a94f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# const\n",
    "DATASET_TYPE = \"byclass\"\n",
    "RAW_DIR      = \"gzip/\"\n",
    "UNPACK_DIR   = f\"unpacked_{DATASET_TYPE}\"\n",
    "NPY_DIR      = \"datasets_npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f71e854",
   "metadata": {},
   "source": [
    "##### Reading, Storing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25cff6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking: c:\\Users\\acer\\Desktop\\PROGRAMMING\\machine_learning\\NumPy-CNN-Handwritten-Digit-Recognition-from-Scratch\\unpacked_byclass\n",
      "gzip directory already exist\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_idx(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        data = np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "    return data\n",
    "\n",
    "def load_emnist_byclass(path=UNPACK_DIR, dataset_type = DATASET_TYPE, np_dataset=NPY_DIR):\n",
    "    if os.path.exists(np_dataset):\n",
    "        return  \n",
    "\n",
    "    # files are inside gzip.zip -> extract first\n",
    "    X_train = read_idx(os.path.join(path, f\"emnist-{dataset_type}-train-images-idx3-ubyte\")) \n",
    "    y_train = read_idx(os.path.join(path, f\"emnist-{dataset_type}-train-labels-idx1-ubyte\")) \n",
    "    X_test  = read_idx(os.path.join(path, f\"emnist-{dataset_type}-test-images-idx3-ubyte\")) \n",
    "    y_test  = read_idx(os.path.join(path, f\"emnist-{dataset_type}-test-labels-idx1-ubyte\")) \n",
    "    \n",
    "    save_binary(X_train, y_train, X_test, y_test)\n",
    "\n",
    "def save_binary(X_train, y_train, X_test, y_test, path=NPY_DIR):\n",
    "    if os.path.exists(path):\n",
    "        return \n",
    "    # create folder \n",
    "    os.makedirs(path)\n",
    "\n",
    "    # save ubyte to binary format \n",
    "    np.save(os.path.join(path, \"X_train.npy\"), X_train.astype(\"float32\") / 255)\n",
    "    np.save(os.path.join(path, \"Y_train.npy\"), y_train.astype(\"float32\"))\n",
    "    np.save(os.path.join(path, \"X_test.npy\"), X_test.astype(\"float32\") / 255)\n",
    "    np.save(os.path.join(path, \"Y_test.npy\"), y_test.astype(\"float32\"))\n",
    "\n",
    "\n",
    "\n",
    "# Define the directory where your files are located\n",
    "def extract_gzip(input_dir = RAW_DIR, data_set_type=DATASET_TYPE):\n",
    "    \"\"\"\"\"\"\n",
    "    unpacked_dir =  f\"unpacked_{data_set_type}\"\n",
    "    # TODO: since uncompressed files are at the same heirarchy as the ain code file find a way for git \n",
    "    #       ignore to to be able to ignore other data set type folder\n",
    "\n",
    "    if os.path.exists(unpacked_dir):\n",
    "        print(\"Checking:\", os.path.abspath(unpacked_dir))\n",
    "        print(\"gzip directory already exist\")\n",
    "        return \n",
    "\n",
    "    # if directory does not exist \n",
    "    print(\"making directory\")\n",
    "    os.makedirs(unpacked_dir)    \n",
    "\n",
    "    # Loop through all files in the specified directory\n",
    "    # example relative path \"gzip\\emnist-digits-test-images-idx3-ubyte.gz\"\n",
    "    for filename in os.listdir(input_dir):\n",
    "        # split the file name for data set type checking \n",
    "        name = filename.split(\"-\")\n",
    "\n",
    "        # Check if the file has a '.gz' extension\n",
    "        if (filename.endswith('.gz')) and name[1] == data_set_type:\n",
    "            # Construct the full path for the compressed file\n",
    "            compressed_filepath = os.path.join(input_dir, filename)\n",
    "\n",
    "            # Create the name for the new uncompressed file by removing the '.gz' extension\n",
    "            uncompressed_filename = os.path.splitext(filename)[0]\n",
    "            uncompressed_filepath = os.path.join(unpacked_dir, uncompressed_filename)\n",
    "\n",
    "            # Open the compressed file and the new uncompressed file\n",
    "            with gzip.open(compressed_filepath, 'rb') as f_in:\n",
    "                with open(uncompressed_filepath, 'wb') as f_out:\n",
    "                    f_out.write(f_in.read())\n",
    "\n",
    "            print(f'\\t- Extracted: {filename} -> {uncompressed_filename}')\n",
    "\n",
    "extract_gzip()\n",
    "load_emnist_byclass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f4fb19",
   "metadata": {},
   "source": [
    "#### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(bitmap_sample):\n",
    "    img = bitmap_sample.squeeze()\n",
    "\n",
    "    f, axes =  plt.subplots(1,2)\n",
    "    axes[0].imshow(np.transpose(img), cmap=\"gray\")\n",
    "    axes[1].imshow(img, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22497b25",
   "metadata": {},
   "source": [
    "#### CNN implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4c1c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m xtrain \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets_npy/X_train.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, mmap_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m ytrain \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets_npy/Y_train.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, mmap_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m xtest \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets_npy/X_test.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, mmap_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "xtrain = np.load(\"datasets_npy/X_train.npy\", mmap_mode='r')\n",
    "ytrain = np.load(\"datasets_npy/Y_train.npy\", mmap_mode='r')\n",
    "xtest = np.load(\"datasets_npy/X_test.npy\", mmap_mode='r')\n",
    "ytest = np.load(\"datasets_npy/Y_test.npy\", mmap_mode='r')\n",
    "\n",
    "# reshape\n",
    "xtrain = xtrain.reshape((*xtrain.shape, 1 ))\n",
    "xtest = xtest.reshape((*xtest.shape, 1 ))\n",
    "\n",
    "idx = np.random.randint(xtest.shape[0])\n",
    "plot_sample(xtest[idx])\n",
    "print(np.shape(xtest[idx]), ytest[idx])\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, fs=5, ps=2):\n",
    "        self.filter_size = fs\n",
    "        self.pool_size = ps\n",
    "\n",
    "    def dense_layer(self, input_vector, output_size, weights=None, bias=None):\n",
    "        \"\"\"\n",
    "        Dense (fully-connected) layer â€” forward pass.\n",
    "\n",
    "        Args:\n",
    "            input_vector:  1D numpy array (shape (input_size,)) OR\n",
    "                        2D numpy array for a batch (shape (batch_size, input_size))\n",
    "                        (If you pass a 1D vector, treat it as a single-example batch.)\n",
    "            output_size:   int, number of neurons in this dense layer (e.g., number of classes)\n",
    "            weights:       optional pre-initialized weight matrix (see shape note below)\n",
    "            bias:          optional pre-initialized bias vector\n",
    "\n",
    "        Returns:\n",
    "            logits: raw scores (shape (output_size,) for single input or\n",
    "                                (batch_size, output_size) for batch input)\n",
    "        \"\"\"\n",
    "\n",
    "        # If user passed a single 1D vector, make it a batch of 1 so dot products work uniformly.\n",
    "        batch_sample = input_vector\n",
    "        single_example = False\n",
    "        if batch_sample.ndim == 1:\n",
    "            batch_sample = batch_sample.reshape((1, batch_sample.shape[0]))\n",
    "            single_example = True\n",
    "\n",
    "        batch_sample = batch_sample.astype(np.float32)\n",
    "\n",
    "        input_size = batch_sample.shape[1]\n",
    "\n",
    "        if weights is None:\n",
    "            scale = sqrt(2 / input_size)\n",
    "            weights = np.random.randn(input_size, output_size) * scale\n",
    "        else:\n",
    "            # If user passed weights, ensure the shape matches what we expect.\n",
    "            # If mismatch, raise a clear error (or reshape if you intend to).\n",
    "            # e.g. if weights.shape != (input_size, output_size): raise ValueError(...)\n",
    "            if weights.shape != (input_size, output_size):\n",
    "                raise ValueError(\"weights shape mismatch\")\n",
    "\n",
    "\n",
    "        if bias is None:\n",
    "            bias =  np.zeros((output_size,), dtype=np.float32)\n",
    "        else:\n",
    "            if bias.shape != (output_size,):\n",
    "                raise ValueError(\"bias shape mismatch\")\n",
    "\n",
    "\n",
    "        if isinstance(weights, np.ndarray) and isinstance(bias, np.ndarray):\n",
    "            logits = batch_sample.dot(weights) + bias   # bias broadcasts across batch dim\n",
    "\n",
    "        # If original input was 1D, return a 1D logits vector (squeeze the batch dim).\n",
    "        if single_example: \n",
    "            return logits.squeeze(0)\n",
    "        # Otherwise return the batched logits.\n",
    "        else: \n",
    "            return logits\n",
    "        \n",
    "\n",
    "\n",
    "    def convolution(self, image, kernel, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image (sample):     2d array / bit image shape (28,28)\n",
    "            kernel (filter):    2d numpy array\n",
    "            stride:             no of steps a filter take\n",
    "\n",
    "        return:\n",
    "            feature map:        \n",
    "        \"\"\"\n",
    "        H,W = image.shape\n",
    "        kH, kW = kernel.shape\n",
    "\n",
    "        feature_y = ((H - kH) // stride) + 1\n",
    "        feature_x = ((W - kW) // stride) + 1\n",
    "\n",
    "        # stores the convultion \n",
    "        feature_map = np.zeros(kH, kW)\n",
    "\n",
    "        for h in range(feature_y):\n",
    "            for w in range(feature_x):\n",
    "                # a snippet of an image \n",
    "                patch = image[h * stride : h * stride + kH, w * stride : w * stride + kW]\n",
    "                feature_map[h,w] = np.sum(kernel * patch)\n",
    "\n",
    "    def reLu(self, feature_map):\n",
    "        \"\"\"\n",
    "        returns activated feature map\n",
    "\n",
    "        args: \n",
    "            feature_map:    2d array recieved from convulution \n",
    "        \"\"\"\n",
    "        # # creates a true or false mask \n",
    "        # mask = feature_map <= 0\n",
    "        # # do reLu based of mask value\n",
    "        # feature_map[mask] = 0\n",
    "        # #return the activated feature map\n",
    "        # return feature_map\n",
    "    \n",
    "        # more effecient way  \n",
    "        return np.maximum(0, feature_map)   # -> compares the feature map element with zero (since 0 > neg num it replaces neg val with 0)\n",
    "\n",
    "    def max_pool(self, feature_map, stride = 2, pool_size=2):\n",
    "        x, y = feature_map.shape\n",
    "\n",
    "        pool_x = ((x - pool_size) // stride) + 1\n",
    "        pool_y = ((y - pool_size) // stride) + 1\n",
    "\n",
    "\n",
    "        pooled_feature = np.zeroes(pool_x, pool_y)\n",
    "\n",
    "        for h in range(pool_y):\n",
    "            for w in range(pool_x):\n",
    "                # snippet of the pool \n",
    "                pool = feature_map[h * stride : h * stride + pool_size, w * stride : w * stride + pool_size]\n",
    "                # chose the highest value within a pool \n",
    "                pooled_feature[h,w] = np.max(pool)\n",
    "\n",
    "        return pooled_feature\n",
    "    def soft_max(Self, logits):\n",
    "        exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))  # Numerical stability improvement\n",
    "        return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "    \n",
    "    def loss_function():\n",
    "        pass\n",
    "    \n",
    "    def flatten(self, pool):\n",
    "        return pool.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c26e84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cnn-env)",
   "language": "python",
   "name": "cnn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
